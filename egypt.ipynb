{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hieroglyph Classification and Custom Data Preparation\n",
    "This notebook implements 3 CNN architectures to classify hieroglyph symbols. It includes data preparation, preprocessing, model training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:19:54.790734Z",
     "iopub.status.busy": "2024-12-29T17:19:54.790409Z",
     "iopub.status.idle": "2024-12-29T17:20:02.939377Z",
     "shell.execute_reply": "2024-12-29T17:20:02.938704Z",
     "shell.execute_reply.started": "2024-12-29T17:19:54.790710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import hashlib\n",
    "import logging\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.applications import Xception,  VGG16, InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Activation, SeparableConv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:05.947077Z",
     "iopub.status.busy": "2024-12-29T17:20:05.946834Z",
     "iopub.status.idle": "2024-12-29T17:20:21.277183Z",
     "shell.execute_reply": "2024-12-29T17:20:21.276482Z",
     "shell.execute_reply.started": "2024-12-29T17:20:05.947055Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Set the dataset path for Kaggle (input folder)\n",
    "data_path = r'D:\\python for data science\\hieroglyph\\egypt'  # Update with your dataset name\n",
    "target_count = 25  # Target number of images per folder\n",
    "balanced_data_path = r'D:\\python for data science\\hieroglyph\\balanced_data'  # New directory for the balanced dataset\n",
    "\n",
    "# Clean the target directory before processing (remove existing files/folders)\n",
    "if os.path.exists(balanced_data_path):\n",
    "    shutil.rmtree(balanced_data_path)  # Delete the directory and all its contents\n",
    "os.makedirs(balanced_data_path, exist_ok=True)  # Recreate the empty directory\n",
    "\n",
    "# Function to ensure the image is grayscale, resized to 100x100, and saved as JPG\n",
    "def process_image(image_path, save_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        image = image.convert('L')\n",
    "\n",
    "        # Resize the image to 100x100 pixels\n",
    "        image_resized = image.resize((100, 100))\n",
    "\n",
    "        # Save the image as JPEG format\n",
    "        image_resized.save(save_path, format=\"JPEG\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# Function to downsample images (in the working directory)\n",
    "def downsample(folder_path, images, target_count):\n",
    "    random.shuffle(images)\n",
    "    for image in images[target_count:]:  # Remove extra images\n",
    "        os.remove(os.path.join(folder_path, image))  # Remove from working directory\n",
    "\n",
    "# Function to apply random augmentations, convert to grayscale, and resize\n",
    "def augment_image(image_path, save_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        image = image.convert('L')\n",
    "\n",
    "        # Apply random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            image = ImageOps.mirror(image)\n",
    "\n",
    "        # Apply random rotation\n",
    "        if random.random() < 0.5:\n",
    "            image = image.rotate(random.choice([90, 180, 270]))  # Rotate by 90, 180, or 270 degrees\n",
    "\n",
    "        # Resize the image to 100x100 pixels\n",
    "        image_resized = image.resize((100, 100))\n",
    "\n",
    "        # Save the image as JPEG format\n",
    "        image_resized.save(save_path, format=\"JPEG\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error augmenting {image_path}: {e}\")\n",
    "\n",
    "# Function to upsample using augmentation and save to the new directory\n",
    "def upsample_and_save_to_new_directory(folder_path, images, target_count, label_folder_name):\n",
    "    # Create the corresponding label folder in the new directory if it doesn't exist\n",
    "    new_label_folder = os.path.join(balanced_data_path, label_folder_name)\n",
    "    os.makedirs(new_label_folder, exist_ok=True)\n",
    "\n",
    "    augmented_images = set()  # Track augmented images to avoid duplication\n",
    "    current_count = len(images)\n",
    "\n",
    "    while current_count < target_count:\n",
    "        image_to_augment = random.choice(images)\n",
    "\n",
    "        # Avoid augmenting the same image repeatedly\n",
    "        if image_to_augment in augmented_images:\n",
    "            continue\n",
    "\n",
    "        # Shorten the augmented image name to prevent long file paths\n",
    "        new_image_name = f\"aug_{current_count}_{os.path.basename(image_to_augment)}\"  # Shortened name\n",
    "        new_image_path = os.path.join(new_label_folder, new_image_name)\n",
    "\n",
    "        # Augment and save the image to the new directory\n",
    "        augment_image(os.path.join(folder_path, image_to_augment), new_image_path)\n",
    "\n",
    "        # Add the augmented image to the list and set\n",
    "        images.append(new_image_name)\n",
    "        augmented_images.add(image_to_augment)\n",
    "        current_count += 1\n",
    "\n",
    "# Process each folder in the dataset\n",
    "for label_folder in os.listdir(data_path):\n",
    "    folder_path = os.path.join(data_path, label_folder)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a folder\n",
    "        images = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        image_count = len(images)\n",
    "\n",
    "        # Ensure the label folder exists in the balanced dataset directory\n",
    "        balanced_label_folder = os.path.join(balanced_data_path, label_folder)\n",
    "        os.makedirs(balanced_label_folder, exist_ok=True)\n",
    "\n",
    "        # Process original images: convert, resize, and save as JPG\n",
    "        for image in images:\n",
    "            original_image_path = os.path.join(folder_path, image)\n",
    "            new_image_path = os.path.join(balanced_label_folder, image)\n",
    "            process_image(original_image_path, new_image_path)  # Convert and save as JPG\n",
    "\n",
    "        # Downsampling or upsampling based on image count\n",
    "        if image_count > target_count:\n",
    "            print(f\"Downsampling {label_folder}: {image_count} -> {target_count}\")\n",
    "            downsample(balanced_label_folder, images, target_count)  # Downsample in the working directory\n",
    "        elif image_count < target_count:\n",
    "            print(f\"Upsampling {label_folder}: {image_count} -> {target_count}\")\n",
    "            upsample_and_save_to_new_directory(balanced_label_folder, images, target_count, label_folder)\n",
    "        else:\n",
    "            print(f\"{label_folder} already balanced with {image_count} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:21.278552Z",
     "iopub.status.busy": "2024-12-29T17:20:21.278238Z",
     "iopub.status.idle": "2024-12-29T17:20:22.399118Z",
     "shell.execute_reply": "2024-12-29T17:20:22.398222Z",
     "shell.execute_reply.started": "2024-12-29T17:20:21.278528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the dataset path from Kaggle's input directory\n",
    "data_path = r'D:\\python for data science\\hieroglyph\\balanced_data'  # Update with your dataset name\n",
    "\n",
    "# Count images in each label folder\n",
    "label_counts = {}\n",
    "for label_folder in os.listdir(data_path):\n",
    "    folder_path = os.path.join(data_path, label_folder)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a folder\n",
    "        num_images = len([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))])  # Count image files\n",
    "        label_counts[label_folder] = num_images\n",
    "\n",
    "# Plot histogram\n",
    "labels = list(label_counts.keys())\n",
    "counts = list(label_counts.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color='skyblue')\n",
    "plt.xlabel('Labels', fontsize=14)\n",
    "plt.ylabel('Number of Images', fontsize=14)\n",
    "plt.title('Number of Images per Label', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:22.400305Z",
     "iopub.status.busy": "2024-12-29T17:20:22.400043Z",
     "iopub.status.idle": "2024-12-29T17:20:23.094697Z",
     "shell.execute_reply": "2024-12-29T17:20:23.093737Z",
     "shell.execute_reply.started": "2024-12-29T17:20:22.400281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the base path of your dataset\n",
    "base_path =  r'D:\\python for data science\\hieroglyph\\balanced_data' \n",
    "\n",
    "# Define the split proportions\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "# Initialize lists for train, validation, and test images\n",
    "train_images = []\n",
    "val_images = []\n",
    "test_images = []\n",
    "labels = []\n",
    "\n",
    "# Traverse through the folders (each folder is a label)\n",
    "for label_folder in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, label_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get all images in the current label folder\n",
    "        images = [os.path.join(folder_path, image) for image in os.listdir(folder_path) if image.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        # Prepare labels for stratified sampling\n",
    "        image_labels = [label_folder] * len(images)\n",
    "\n",
    "        # Stratified train/validation/test split\n",
    "        train, temp, train_labels, temp_labels = train_test_split(\n",
    "            images, image_labels, train_size=train_size, stratify=image_labels, random_state=42\n",
    "        )\n",
    "        val, test, val_labels, test_labels = train_test_split(\n",
    "            temp, temp_labels, test_size=test_size/(test_size+val_size), stratify=temp_labels, random_state=42\n",
    "        )\n",
    "\n",
    "        # Append to the final lists\n",
    "        train_images.extend(train)\n",
    "        val_images.extend(val)\n",
    "        test_images.extend(test)\n",
    "\n",
    "        # Add corresponding labels\n",
    "        labels.extend(train_labels)\n",
    "        labels.extend(val_labels)\n",
    "        labels.extend(test_labels)\n",
    "\n",
    "# Check the result of the split\n",
    "print(f\"Train images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "\n",
    "# Optionally, you can move the files to new directories for training, validation, and testing\n",
    "def move_files(image_paths, target_folder):\n",
    "    for image_path in image_paths:\n",
    "        label_folder = os.path.basename(os.path.dirname(image_path))  # Extract label from folder name\n",
    "        target_label_folder = os.path.join(target_folder, label_folder)\n",
    "        os.makedirs(target_label_folder, exist_ok=True)\n",
    "        shutil.copy(image_path, target_label_folder)\n",
    "\n",
    "# Define the output directories for the split datasets\n",
    "train_dir =r'D:\\python for data science\\hieroglyph\\train'\n",
    "val_dir =r'D:\\python for data science\\hieroglyph\\val'\n",
    "test_dir =r'D:\\python for data science\\hieroglyph\\test'\n",
    "\n",
    "# Move images to corresponding directories\n",
    "move_files(train_images, train_dir)\n",
    "move_files(val_images, val_dir)\n",
    "move_files(test_images, test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:23.096026Z",
     "iopub.status.busy": "2024-12-29T17:20:23.095699Z",
     "iopub.status.idle": "2024-12-29T17:20:24.050389Z",
     "shell.execute_reply": "2024-12-29T17:20:24.049516Z",
     "shell.execute_reply.started": "2024-12-29T17:20:23.095993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define the base path for your train dataset\n",
    "train_dir =r'D:\\python for data science\\hieroglyph\\train'  # Update this with your train dataset path\n",
    "\n",
    "# Collect all image paths and their corresponding labels\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "for label_folder in os.listdir(train_dir):\n",
    "    folder_path = os.path.join(train_dir, label_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get all images in the current label folder\n",
    "        for image in os.listdir(folder_path):\n",
    "            if image.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_paths.append(os.path.join(folder_path, image))\n",
    "                image_labels.append(label_folder)\n",
    "\n",
    "# Randomly select a small patch of images (e.g., 9 images)\n",
    "num_images = 9  # Number of images to display\n",
    "selected_indices = random.sample(range(len(image_paths)), num_images)\n",
    "\n",
    "# Create a subplot for displaying images\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))  # 3x3 grid for 9 images\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the selected images with their labels\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    image_path = image_paths[idx]\n",
    "    label = image_labels[idx]\n",
    "\n",
    "    # Open and display the image\n",
    "    image = Image.open(image_path)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(label, fontsize=12)\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:24.051554Z",
     "iopub.status.busy": "2024-12-29T17:20:24.051278Z",
     "iopub.status.idle": "2024-12-29T17:20:28.683042Z",
     "shell.execute_reply": "2024-12-29T17:20:28.682132Z",
     "shell.execute_reply.started": "2024-12-29T17:20:24.051528Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Path to the train dataset\n",
    "data_path = r\"D:\\python for data science\\hieroglyph\\train\"\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# List all class labels (folder names)\n",
    "allowed_labels = os.listdir(data_path)\n",
    "\n",
    "for label in allowed_labels:\n",
    "    class_folder = os.path.join(data_path, label)\n",
    "    \n",
    "    if os.path.isdir(class_folder):  # Check if it is a directory\n",
    "        for file in os.listdir(class_folder):\n",
    "            file_path = os.path.join(class_folder, file)\n",
    "            \n",
    "            try:\n",
    "                # Load the image and convert it to an array\n",
    "                img = load_img(file_path, target_size=(299, 299))  # Resize the image to 299x299\n",
    "                img_array = img_to_array(img) / 255.0  # Normalize the image to [0, 1]\n",
    "                \n",
    "                # Append the image array and corresponding label\n",
    "                X_train.append(img_array)\n",
    "                y_train.append(label)  # Class label as string\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {file_path}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(X_train)} images with {len(np.unique(y_train))} unique labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:28.685779Z",
     "iopub.status.busy": "2024-12-29T17:20:28.685534Z",
     "iopub.status.idle": "2024-12-29T17:20:30.040345Z",
     "shell.execute_reply": "2024-12-29T17:20:30.039624Z",
     "shell.execute_reply.started": "2024-12-29T17:20:28.685757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "val_data_path = r\"D:\\python for data science\\hieroglyph\\val\"\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for label in os.listdir(val_data_path):\n",
    "    class_folder = os.path.join(val_data_path, label)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for file in os.listdir(class_folder):\n",
    "            file_path = os.path.join(class_folder, file)\n",
    "            try:\n",
    "                img = load_img(file_path, target_size=(299, 299))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                X_val.append(img_array)\n",
    "                y_val.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(f\"Loaded {len(X_val)} validation images with {len(np.unique(y_val))}labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:30.041780Z",
     "iopub.status.busy": "2024-12-29T17:20:30.041476Z",
     "iopub.status.idle": "2024-12-29T17:20:31.194073Z",
     "shell.execute_reply": "2024-12-29T17:20:31.193147Z",
     "shell.execute_reply.started": "2024-12-29T17:20:30.041757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_data_path = r\"D:\\python for data science\\hieroglyph\\test\"\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for label in os.listdir(test_data_path):\n",
    "    class_folder = os.path.join(test_data_path, label)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for file in os.listdir(class_folder):\n",
    "            file_path = os.path.join(class_folder, file)\n",
    "            try:\n",
    "                img = load_img(file_path, target_size=(299, 299))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                X_test.append(img_array)\n",
    "                y_test.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Loaded {len(X_test)} test images with {len(np.unique(y_test))} labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:31.195374Z",
     "iopub.status.busy": "2024-12-29T17:20:31.195067Z",
     "iopub.status.idle": "2024-12-29T17:20:31.202956Z",
     "shell.execute_reply": "2024-12-29T17:20:31.202238Z",
     "shell.execute_reply.started": "2024-12-29T17:20:31.195342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert class labels to integer values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_train_one_hot = to_categorical(y_train_encoded)  # One-hot encode the integer labels\n",
    "\n",
    "# Encode validation labels\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_val_one_hot = to_categorical(y_val_encoded, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Encode and one-hot encode test labels\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_test_one_hot = to_categorical(y_test_encoded, num_classes=len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:31.204079Z",
     "iopub.status.busy": "2024-12-29T17:20:31.203850Z",
     "iopub.status.idle": "2024-12-29T17:20:31.213049Z",
     "shell.execute_reply": "2024-12-29T17:20:31.212300Z",
     "shell.execute_reply.started": "2024-12-29T17:20:31.204058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_vgg16_transfer_model(input_shape, n_classes, learning_rate=1e-4):\n",
    "    # Load VGG16 with pretrained ImageNet weights\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add custom top layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)  # Flatten the output for Dense layers\n",
    "    x = Dense(4096, activation='relu')(x)  # Emulating AlexNet's dense layers\n",
    "    x = Dropout(0.5)(x)  # Dropout to prevent overfitting\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_classes, activation='softmax')(x)  # Final classification layer\n",
    "    \n",
    "    # Compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:31.214180Z",
     "iopub.status.busy": "2024-12-29T17:20:31.213885Z",
     "iopub.status.idle": "2024-12-29T17:20:31.224158Z",
     "shell.execute_reply": "2024-12-29T17:20:31.223497Z",
     "shell.execute_reply.started": "2024-12-29T17:20:31.214149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_inceptionv3_model(input_shape, n_classes, learning_rate=1e-4):\n",
    "    # Use TensorFlow ImageNet weights directly\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers with regularization and dropout\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)  # Prevent overfitting\n",
    "    output = Dense(n_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "    # Define and compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:31.225179Z",
     "iopub.status.busy": "2024-12-29T17:20:31.224905Z",
     "iopub.status.idle": "2024-12-29T17:20:31.237771Z",
     "shell.execute_reply": "2024-12-29T17:20:31.237115Z",
     "shell.execute_reply.started": "2024-12-29T17:20:31.225151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_xception_model(input_shape, n_classes, learning_rate=1e-4):\n",
    "    weights_path = r'D:\\python for data science\\hieroglyph\\xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    base_model = Xception(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights(weights_path)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers with regularization and dropout\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)  # Add dropout to prevent overfitting\n",
    "    output = Dense(n_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:31.238787Z",
     "iopub.status.busy": "2024-12-29T17:20:31.238507Z",
     "iopub.status.idle": "2024-12-29T17:20:32.310458Z",
     "shell.execute_reply": "2024-12-29T17:20:32.309781Z",
     "shell.execute_reply.started": "2024-12-29T17:20:31.238759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Apply the augmentation to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Train Models\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:20:32.311567Z",
     "iopub.status.busy": "2024-12-29T17:20:32.311299Z",
     "iopub.status.idle": "2024-12-29T17:34:20.822403Z",
     "shell.execute_reply": "2024-12-29T17:34:20.821294Z",
     "shell.execute_reply.started": "2024-12-29T17:20:32.311543Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VGG16\n",
    "print(\"Training VGG16...\")\n",
    "vgg16_model = build_vgg16_transfer_model(input_shape=(299, 299, 3), n_classes=len(label_encoder.classes_), learning_rate=1e-4)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    X_train, y_train_one_hot, batch_size=32,\n",
    "    validation_data=(X_val, y_val_one_hot),\n",
    "    epochs=25,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate on Test Data\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"VGG16 Test Accuracy: {vgg16_test_accuracy:.2f}\")\n",
    "\n",
    "# Save Results\n",
    "results[\"VGG16\"] = {\"model\": vgg16_model, \"history\": vgg16_history, \"test_accuracy\": vgg16_test_accuracy}\n",
    "vgg16_model.save_weights(\"VGG16_model.weights.h5\")\n",
    "vgg16_model.save(\"VGG16_model.h5\")\n",
    "print(\"VGG16 weights and model saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:35:26.995232Z",
     "iopub.status.busy": "2024-12-29T17:35:26.994761Z",
     "iopub.status.idle": "2024-12-29T17:41:04.600149Z",
     "shell.execute_reply": "2024-12-29T17:41:04.599373Z",
     "shell.execute_reply.started": "2024-12-29T17:35:26.995192Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training InceptionV3...\n",
      "Epoch 1/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - accuracy: 0.0289 - loss: 14.3820 - val_accuracy: 0.1886 - val_loss: 12.8145\n",
      "Epoch 2/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.1393 - loss: 11.7688 - val_accuracy: 0.4167 - val_loss: 10.6679\n",
      "Epoch 3/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.2546 - loss: 9.9687 - val_accuracy: 0.5468 - val_loss: 9.1378\n",
      "Epoch 4/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.3784 - loss: 8.6530 - val_accuracy: 0.6520 - val_loss: 8.0350\n",
      "Epoch 5/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.4847 - loss: 7.6692 - val_accuracy: 0.6784 - val_loss: 7.2209\n",
      "Epoch 6/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.5445 - loss: 6.9665 - val_accuracy: 0.7383 - val_loss: 6.5795\n",
      "Epoch 7/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 1s/step - accuracy: 0.5834 - loss: 6.3887 - val_accuracy: 0.7690 - val_loss: 6.1027\n",
      "Epoch 8/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.6230 - loss: 5.9399 - val_accuracy: 0.7778 - val_loss: 5.6827\n",
      "Epoch 9/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.6512 - loss: 5.5529 - val_accuracy: 0.8026 - val_loss: 5.3398\n",
      "Epoch 10/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.6705 - loss: 5.2500 - val_accuracy: 0.7968 - val_loss: 5.0594\n",
      "Epoch 11/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.6945 - loss: 4.9604 - val_accuracy: 0.8187 - val_loss: 4.8115\n",
      "Epoch 12/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 1s/step - accuracy: 0.7097 - loss: 4.7263 - val_accuracy: 0.8099 - val_loss: 4.5928\n",
      "Epoch 13/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.7210 - loss: 4.5203 - val_accuracy: 0.8246 - val_loss: 4.4171\n",
      "Epoch 14/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 1s/step - accuracy: 0.7396 - loss: 4.3371 - val_accuracy: 0.8099 - val_loss: 4.2585\n",
      "Epoch 15/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 1s/step - accuracy: 0.7437 - loss: 4.1965 - val_accuracy: 0.8319 - val_loss: 4.1098\n",
      "Epoch 16/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.7681 - loss: 4.0444 - val_accuracy: 0.8289 - val_loss: 3.9960\n",
      "Epoch 17/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 1s/step - accuracy: 0.7623 - loss: 3.9184 - val_accuracy: 0.8363 - val_loss: 3.8798\n",
      "Epoch 18/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.7644 - loss: 3.8497 - val_accuracy: 0.8450 - val_loss: 3.7820\n",
      "Epoch 19/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - accuracy: 0.7816 - loss: 3.7387 - val_accuracy: 0.8304 - val_loss: 3.7088\n",
      "Epoch 20/20\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 1s/step - accuracy: 0.7836 - loss: 3.6496 - val_accuracy: 0.8304 - val_loss: 3.6257\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8713 - loss: 3.5647\n",
      "InceptionV3 Test Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 weights and model saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# InceptionV3\n",
    "print(\"Training InceptionV3...\")\n",
    "\n",
    "inceptionv3_model = build_inceptionv3_model(input_shape=(299, 299, 3), n_classes=len(label_encoder.classes_))\n",
    "inceptionv3_history = inceptionv3_model.fit(X_train, y_train_one_hot, batch_size=16,\n",
    "                                        validation_data=(X_val, y_val_one_hot),\n",
    "                                        epochs=20)\n",
    "\n",
    "inceptionv3_test_loss, inceptionv3_test_accuracy = inceptionv3_model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"InceptionV3 Test Accuracy: {inceptionv3_test_accuracy:.2f}\")\n",
    "results[\"InceptionV3\"] = {\"model\": inceptionv3_model, \"history\": inceptionv3_history, \"test_accuracy\": inceptionv3_test_accuracy}\n",
    "inceptionv3_model.save_weights(\"InceptionV3_model.weights.h5\")\n",
    "inceptionv3_model.save(\"InceptionV3_model.h5\")\n",
    "print(\"InceptionV3 weights and model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T17:56:39.981081Z",
     "iopub.status.busy": "2024-12-29T17:56:39.980743Z",
     "iopub.status.idle": "2024-12-29T18:06:56.964162Z",
     "shell.execute_reply": "2024-12-29T18:06:56.963074Z",
     "shell.execute_reply.started": "2024-12-29T17:56:39.981058Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Xception\n",
    "\n",
    "print(\"Training Xception...\")\n",
    "\n",
    "xception_model = build_xception_model(input_shape=(299, 299, 3), n_classes=len(label_encoder.classes_))\n",
    "xception_history = xception_model.fit(\n",
    "    X_train, y_train_one_hot, batch_size=16,\n",
    "    validation_data=(X_val, y_val_one_hot),\n",
    "    epochs=25\n",
    ")\n",
    "\n",
    "xception_test_loss, xception_test_accuracy = xception_model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Xception Test Accuracy: {xception_test_accuracy:.2f}\")\n",
    "results[\"Xception\"] = {\"model\": xception_model, \"history\": xception_history, \"test_accuracy\": xception_test_accuracy}\n",
    "xception_model.save_weights(\"Xception_model.weights.h5\")\n",
    "xception_model.save(\"Xception_model.h5\")\n",
    "print(\"Xception weights and model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:06:56.965979Z",
     "iopub.status.busy": "2024-12-29T18:06:56.965695Z",
     "iopub.status.idle": "2024-12-29T18:06:57.448202Z",
     "shell.execute_reply": "2024-12-29T18:06:57.447342Z",
     "shell.execute_reply.started": "2024-12-29T18:06:56.965954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compare Training and Validation Accuracy\n",
    "plt.figure(figsize=(12, 8))\n",
    "for arch_name, result in results.items():\n",
    "    plt.plot(result[\"history\"].history[\"accuracy\"], label=f\"{arch_name} Train Accuracy\")\n",
    "    plt.plot(result[\"history\"].history[\"val_accuracy\"], label=f\"{arch_name} Val Accuracy\")\n",
    "\n",
    "plt.title(\"Training and Validation Accuracy for All Architectures\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Compare Training and Validation Loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "for arch_name, result in results.items():\n",
    "    plt.plot(result[\"history\"].history[\"loss\"], label=f\"{arch_name} Train Loss\")\n",
    "    plt.plot(result[\"history\"].history[\"val_loss\"], label=f\"{arch_name} Val Loss\")\n",
    "\n",
    "plt.title(\"Training and Validation Loss for All Architectures\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print Test Accuracy for Each Model\n",
    "for arch_name, result in results.items():\n",
    "    print(f\"{arch_name}: Test Accuracy = {result['test_accuracy']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:06:57.449958Z",
     "iopub.status.busy": "2024-12-29T18:06:57.449735Z",
     "iopub.status.idle": "2024-12-29T18:07:19.890216Z",
     "shell.execute_reply": "2024-12-29T18:07:19.889400Z",
     "shell.execute_reply.started": "2024-12-29T18:06:57.449938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Plot confusion matrix for each model\n",
    "for model_name, result in results.items():\n",
    "    print(f\"\\nConfusion Matrix for {model_name}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = result[\"model\"].predict(X_test)\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_true_classes = y_test_one_hot.argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Comparison Table of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T18:07:19.891416Z",
     "iopub.status.busy": "2024-12-29T18:07:19.891145Z",
     "iopub.status.idle": "2024-12-29T18:07:37.171347Z",
     "shell.execute_reply": "2024-12-29T18:07:37.170241Z",
     "shell.execute_reply.started": "2024-12-29T18:07:19.891393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Collect metrics\n",
    "comparison_metrics = []\n",
    "for model_name, result in results.items():\n",
    "    y_pred = result[\"model\"].predict(X_test)\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_true_classes = y_test_one_hot.argmax(axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision = precision_score(y_true_classes, y_pred_classes, average=\"weighted\")\n",
    "    recall = recall_score(y_true_classes, y_pred_classes, average=\"weighted\")\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average=\"weighted\")\n",
    "    \n",
    "    comparison_metrics.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to summarize results\n",
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame(comparison_metrics)\n",
    "print(metrics_df)\n",
    "\n",
    "# Visualize the comparison\n",
    "metrics_df.set_index(\"Model\").plot(kind=\"bar\", figsize=(12, 8))\n",
    "plt.title(\"Comparison of Metrics for All Models\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "plt.xlabel(\"Model\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6385891,
     "sourceId": 10315029,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6386040,
     "sourceId": 10315284,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 203249,
     "modelInstanceId": 181022,
     "sourceId": 212357,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 204055,
     "modelInstanceId": 181821,
     "sourceId": 213311,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 204056,
     "modelInstanceId": 181822,
     "sourceId": 213312,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
